{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delta Method for Parameter Inference\n",
    "\n",
    "- Analytic technique for approximating variances and constructing confidence intervals for functions of estimators.\n",
    "- Relies on asymptotic normality and differentiable transformations.\n",
    "- Applicable to both univariate and multivariate estimators.\n",
    "\n",
    "### Process\n",
    "\n",
    "1. Compute the parameter estimate using the full sample:\n",
    "   - $ \\hat{\\theta}_n = g(X_1, X_2, \\dots, X_N) $\n",
    "\n",
    "2. Define the function and compute its gradient:\n",
    "   - Identify the function $ g(\\cdot) $ of interest.\n",
    "   - Calculate the gradient $ \\nabla g(\\hat{\\theta}_n) $.\n",
    "\n",
    "3. Estimate the variance-covariance matrix of the estimator:\n",
    "   - $ \\Sigma = \\text{Var}(\\hat{\\theta}_n) $\n",
    "\n",
    "4. Apply the delta method to approximate the variance of $ g(\\hat{\\theta}_n) $:\n",
    "   - $ \\text{Var}(g(\\hat{\\theta}_n)) \\approx \\nabla g(\\hat{\\theta}_n)' \\Sigma \\nabla g(\\hat{\\theta}_n) $\n",
    "\n",
    "5. Construct the confidence interval:\n",
    "   - $ g(\\hat{\\theta}_n) \\pm z_{\\alpha/2} \\times \\sqrt{\\text{Var}(g(\\hat{\\theta}_n))} $\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- Computationally efficient compared to resampling methods like bootstrap.\n",
    "- Widely applicable to various nonlinear functions of parameters.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- Large sample requirement: Relies on asymptotic properties; may be inaccurate for small samples.\n",
    "- Differentiability assumption: Requires the function $ g(\\theta) $ to be differentiable.\n",
    "- Linear approximation: May fail for highly nonlinear functions or when higher-order terms are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>StdErr</th>\n",
       "      <th>t</th>\n",
       "      <th>p-value</th>\n",
       "      <th>95% CI Lower</th>\n",
       "      <th>95% CI Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>2.2261</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>18.5334</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.9907</td>\n",
       "      <td>2.4615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>0.9877</td>\n",
       "      <td>0.1144</td>\n",
       "      <td>8.6353</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>1.2119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1/b2</th>\n",
       "      <td>2.2538</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>8.2713</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.7197</td>\n",
       "      <td>2.7878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coefficient  StdErr       t  p-value  95% CI Lower  95% CI Upper\n",
       "b1          2.2261  0.1201 18.5334   0.0000        1.9907        2.4615\n",
       "b2          0.9877  0.1144  8.6353   0.0000        0.7635        1.2119\n",
       "b1/b2       2.2538  0.2725  8.2713   0.0000        1.7197        2.7878"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# 1. Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "x1 = np.random.randn(n)\n",
    "x2 = np.random.randn(n)\n",
    "y = 2 * x1 + 1 * x2 + np.random.randn(n)  # True b1=2, b2=1\n",
    "\n",
    "# 2. OLS estimates by hand\n",
    "X = np.column_stack([np.ones(n), x1, x2])       # Design matrix: intercept + x1 + x2\n",
    "XtX = X.T @ X\n",
    "XtX_inv = np.linalg.inv(XtX)\n",
    "b_hat = XtX_inv @ X.T @ y                      # (X'X)^{-1}X'y\n",
    "\n",
    "# 3. Residual variance\n",
    "resid = y - X @ b_hat\n",
    "sigma2 = np.sum(resid**2) / (n - X.shape[1])    # Unbiased estimator of error variance\n",
    "\n",
    "# 4. Variance-Covariance matrix of parameters\n",
    "cov_b = sigma2 * XtX_inv\n",
    "\n",
    "# 5. Extract estimates for b1 and b2\n",
    "b0, b1, b2 = b_hat\n",
    "se_b1 = np.sqrt(cov_b[1, 1])\n",
    "se_b2 = np.sqrt(cov_b[2, 2])\n",
    "\n",
    "# 6. Compute t-statistics and p-values for b1 and b2\n",
    "t_b1 = b1 / se_b1\n",
    "t_b2 = b2 / se_b2\n",
    "p_b1 = 2 * (1 - stats.norm.cdf(np.abs(t_b1)))\n",
    "p_b2 = 2 * (1 - stats.norm.cdf(np.abs(t_b2)))\n",
    "\n",
    "# 7. Compute 95% Confidence Intervals for b1 and b2\n",
    "ci_b1_lower = b1 - 1.96 * se_b1\n",
    "ci_b1_upper = b1 + 1.96 * se_b1\n",
    "ci_b2_lower = b2 - 1.96 * se_b2\n",
    "ci_b2_upper = b2 + 1.96 * se_b2\n",
    "\n",
    "# 8. Ratio and Delta Method\n",
    "ratio = b1 / b2\n",
    "# Gradient of g(b1, b2) = b1 / b2 w.r.t b1 and b2\n",
    "grad = np.array([1 / b2, -b1 / (b2 ** 2)])\n",
    "# Extract covariance between b1 and b2\n",
    "cov_b1_b2 = cov_b[1, 2]\n",
    "cov_b2_b1 = cov_b[2, 1]\n",
    "# Variance of the ratio using Delta Method\n",
    "var_ratio = grad[0]**2 * cov_b[1, 1] + grad[1]**2 * cov_b[2, 2] + 2 * grad[0] * grad[1] * cov_b1_b2\n",
    "se_ratio = np.sqrt(var_ratio)\n",
    "# t-statistic and p-value for ratio\n",
    "t_ratio = ratio / se_ratio\n",
    "p_ratio = 2 * (1 - stats.norm.cdf(np.abs(t_ratio)))\n",
    "# 95% Confidence Interval for ratio\n",
    "ci_ratio_lower = ratio - 1.96 * se_ratio\n",
    "ci_ratio_upper = ratio + 1.96 * se_ratio\n",
    "\n",
    "# 9. Assemble Results into a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'Coefficient': [b1, b2, ratio],\n",
    "    'StdErr': [se_b1, se_b2, se_ratio],\n",
    "    't': [t_b1, t_b2, t_ratio],\n",
    "    'p-value': [p_b1, p_b2, p_ratio],\n",
    "    '95% CI Lower': [ci_b1_lower, ci_b2_lower, ci_ratio_lower],\n",
    "    '95% CI Upper': [ci_b1_upper, ci_b2_upper, ci_ratio_upper]\n",
    "}, index=['b1', 'b2', 'b1/b2'])\n",
    "\n",
    "# 10. Formatting the Results\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>StdErr</th>\n",
       "      <th>z-value</th>\n",
       "      <th>p-value</th>\n",
       "      <th>CI Lower</th>\n",
       "      <th>CI Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b0</th>\n",
       "      <td>-0.9921</td>\n",
       "      <td>0.1348</td>\n",
       "      <td>-7.3626</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.2562</td>\n",
       "      <td>-0.7280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1</th>\n",
       "      <td>1.9712</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>10.4171</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.6003</td>\n",
       "      <td>2.3421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2</th>\n",
       "      <td>-0.8143</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>-5.8604</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0866</td>\n",
       "      <td>-0.5420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b1/b2</th>\n",
       "      <td>-2.4207</td>\n",
       "      <td>0.4180</td>\n",
       "      <td>-5.7911</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-3.2400</td>\n",
       "      <td>-1.6014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coefficient  StdErr  z-value  p-value  CI Lower  CI Upper\n",
       "b0         -0.9921  0.1348  -7.3626   0.0000   -1.2562   -0.7280\n",
       "b1          1.9712  0.1892  10.4171   0.0000    1.6003    2.3421\n",
       "b2         -0.8143  0.1389  -5.8604   0.0000   -1.0866   -0.5420\n",
       "b1/b2      -2.4207  0.4180  -5.7911   0.0000   -3.2400   -1.6014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "np.random.seed(42)\n",
    "\n",
    "# 1. Generate synthetic logistic data\n",
    "n = 500\n",
    "x1 = np.random.randn(n)\n",
    "x2 = np.random.randn(n)\n",
    "X = np.column_stack([np.ones(n), x1, x2])  # intercept + x1 + x2\n",
    "beta_true = np.array([-1.0, 2.0, -1.0])\n",
    "p = 1 / (1 + np.exp(-X @ beta_true))\n",
    "y = np.random.binomial(1, p)\n",
    "\n",
    "# 2. Define log-likelihood, gradient, Hessian for logistic\n",
    "def loglike(b):\n",
    "    xb = X @ b\n",
    "    return -np.sum(y * xb - np.log(1 + np.exp(xb)))\n",
    "\n",
    "def grad_loglike(b):\n",
    "    xb = X @ b\n",
    "    p = 1 / (1 + np.exp(-xb))  # predicted probabilities\n",
    "    return -(X.T @ (y - p))\n",
    "\n",
    "def hess_loglike(b):\n",
    "    xb = X @ b\n",
    "    p = 1 / (1 + np.exp(-xb))\n",
    "    W = np.diag(p * (1 - p))\n",
    "    return X.T @ W @ X\n",
    "\n",
    "# 3. Newton-Raphson to find MLE\n",
    "b = np.zeros(X.shape[1])  # init\n",
    "for _ in range(20):  # simple fixed iteration\n",
    "    g = grad_loglike(b)\n",
    "    H = hess_loglike(b)\n",
    "    b -= np.linalg.inv(H) @ g\n",
    "\n",
    "# 4. Invert Hessian to get covariance\n",
    "cov_b = np.linalg.inv(hess_loglike(b))\n",
    "\n",
    "# 5. Extract parameter estimates, std. errors\n",
    "b0, b1, b2 = b\n",
    "se_b0 = np.sqrt(cov_b[0, 0])\n",
    "se_b1 = np.sqrt(cov_b[1, 1])\n",
    "se_b2 = np.sqrt(cov_b[2, 2])\n",
    "\n",
    "# 6. Delta Method for a ratio g(b1, b2) = b1 / b2\n",
    "ratio = b1 / b2\n",
    "grad = np.array([1 / b2, -b1 / (b2**2)])  # partial w.r.t. [b1, b2]\n",
    "cov_12 = cov_b[1:3, 1:3]  # submatrix for b1, b2\n",
    "var_ratio = grad @ cov_12 @ grad\n",
    "se_ratio = np.sqrt(var_ratio)\n",
    "\n",
    "# 7. Construct table\n",
    "z = 1.96\n",
    "def ci(est, se): \n",
    "    return (est - z * se, est + z * se)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Coefficient': [b0, b1, b2, ratio],\n",
    "    'StdErr':      [se_b0, se_b1, se_b2, se_ratio],\n",
    "    'z-value':     [b0/se_b0, b1/se_b1, b2/se_b2, ratio/se_ratio],\n",
    "    'p-value':     [2*(1 - norm.cdf(abs(b0/se_b0))),\n",
    "                    2*(1 - norm.cdf(abs(b1/se_b1))),\n",
    "                    2*(1 - norm.cdf(abs(b2/se_b2))),\n",
    "                    2*(1 - norm.cdf(abs(ratio/se_ratio)))]\n",
    "}, index=['b0','b1','b2','b1/b2'])\n",
    "\n",
    "results['CI Lower'], results['CI Upper'] = zip(*results.apply(\n",
    "    lambda row: ci(row['Coefficient'], row['StdErr']), axis=1\n",
    "))\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimate</th>\n",
       "      <th>DeltaMethod_SE</th>\n",
       "      <th>MC_SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-0.9572</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.1579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>1.6647</td>\n",
       "      <td>0.1953</td>\n",
       "      <td>0.2157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>-0.9754</td>\n",
       "      <td>0.1535</td>\n",
       "      <td>0.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Probability</th>\n",
       "      <td>0.5897</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Estimate  DeltaMethod_SE  MC_SE\n",
       "Intercept               -0.9572          0.1457 0.1579\n",
       "x1                       1.6647          0.1953 0.2157\n",
       "x2                      -0.9754          0.1535 0.1667\n",
       "Predicted Probability    0.5897          0.0368 0.0401"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "np.random.seed(42)\n",
    "\n",
    "def sim_data(n=400):\n",
    "    x1 = np.random.randn(n)\n",
    "    x2 = np.random.randn(n)\n",
    "    X = np.column_stack([np.ones(n), x1, x2])\n",
    "    b_true = np.array([-1.0, 2.0, -1.0])\n",
    "    p_true = 1 / (1 + np.exp(-X @ b_true))\n",
    "    y = np.random.binomial(1, p_true)\n",
    "    return X, y\n",
    "\n",
    "def fit_logistic(X, y):\n",
    "    def grad(b):\n",
    "        xb = X @ b\n",
    "        p = 1 / (1 + np.exp(-xb))\n",
    "        return -(X.T @ (y - p))\n",
    "    def hess(b):\n",
    "        xb = X @ b\n",
    "        p = 1 / (1 + np.exp(-xb))\n",
    "        W = p * (1 - p)\n",
    "        return X.T @ (W[:,None] * X)\n",
    "    b = np.zeros(X.shape[1])\n",
    "    for _ in range(100):\n",
    "        g = grad(b)\n",
    "        H = hess(b)\n",
    "        d = np.linalg.solve(H, g)\n",
    "        b_new = b - d\n",
    "        if np.max(np.abs(d)) < 1e-6:\n",
    "            b = b_new\n",
    "            break\n",
    "        b = b_new\n",
    "    cov_b = np.linalg.inv(hess(b))\n",
    "    return b, cov_b\n",
    "\n",
    "X, y = sim_data()\n",
    "b_hat, cov_b = fit_logistic(X, y)\n",
    "se_delta = np.sqrt(np.diag(cov_b))\n",
    "x0 = np.array([1, 0.5, -0.5])\n",
    "phat = 1 / (1 + np.exp(-x0 @ b_hat))\n",
    "gp = phat * (1 - phat) * x0\n",
    "var_phat = gp @ cov_b @ gp\n",
    "se_phat = np.sqrt(var_phat)\n",
    "\n",
    "M = 1000\n",
    "b_store = []\n",
    "p_store = []\n",
    "for _ in range(M):\n",
    "    Xmc, ymc = sim_data()\n",
    "    b_mc, _ = fit_logistic(Xmc, ymc)\n",
    "    b_store.append(b_mc)\n",
    "    p_store.append(1 / (1 + np.exp(-x0 @ b_mc)))\n",
    "b_store = np.vstack(b_store)\n",
    "p_store = np.array(p_store)\n",
    "\n",
    "mc_se_b = b_store.std(axis=0)\n",
    "mc_se_phat = p_store.std()\n",
    "\n",
    "ix = ['Intercept','x1','x2','Predicted Probability']\n",
    "df = pd.DataFrame({\n",
    "    'Estimate':     list(b_hat) + [phat],\n",
    "    'DeltaMethod_SE': list(se_delta) + [se_phat],\n",
    "    'MC_SE':        list(mc_se_b) + [mc_se_phat]\n",
    "}, index=ix)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Method  Coverage  Avg Time (s)\n",
      "0     NB    0.9100        0.0233\n",
      "1    Pre    0.9450        0.0000\n",
      "2   Post    1.0000        0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def true_quantile_normal(p=0.95):  \n",
    "    # 95% quantile for standard normal ~ 1.645\n",
    "    from math import sqrt, log\n",
    "    from scipy.stats import norm\n",
    "    return norm.ppf(p)\n",
    "\n",
    "def bootstrap_ci(x, p=0.95, B=500, alpha=0.05):\n",
    "    n = len(x)\n",
    "    q_list = []\n",
    "    for _ in range(B):\n",
    "        xb = np.random.choice(x, size=n, replace=True)\n",
    "        q_list.append(np.quantile(xb, p))\n",
    "    q_arr = np.sort(q_list)\n",
    "    lo = q_arr[int(alpha/2*B)]\n",
    "    hi = q_arr[int((1 - alpha/2)*B)]\n",
    "    return lo, hi\n",
    "\n",
    "def outer_ci_pre(x, p=0.95, alpha=0.05):\n",
    "    # 1) Find raw quantile\n",
    "    n = len(x)\n",
    "    x_sorted = np.sort(x)\n",
    "    q_idx = int(np.floor(p*n))\n",
    "    Qp = x_sorted[q_idx]\n",
    "    # 2) Indicator\n",
    "    y = (x <= Qp).astype(float)\n",
    "    # 3) Summaries\n",
    "    ybar = y.mean()\n",
    "    # 4) Delta approximation of p(1-p)/n scaled by clusters=1 for simplicity\n",
    "    se = np.sqrt((ybar*(1-ybar))/n)\n",
    "    z = 1.96\n",
    "    lo_rank = max(0, int(n*(p - z*se)))\n",
    "    hi_rank = min(n-1, int(n*(p + z*se)))\n",
    "    return x_sorted[lo_rank], x_sorted[hi_rank]\n",
    "\n",
    "def outer_ci_post(x, p=0.95, alpha=0.05):\n",
    "    n = len(x)\n",
    "    x_sorted = np.sort(x)\n",
    "    # naive ranks\n",
    "    se_naive = np.sqrt(p*(1-p)/n)\n",
    "    z = 1.96\n",
    "    lo_rank = max(0, int(n*(p - z*se_naive)))\n",
    "    hi_rank = min(n-1, int(n*(p + z*se_naive)))\n",
    "    # unadjusted CI\n",
    "    lo_unadj = x_sorted[lo_rank]\n",
    "    hi_unadj = x_sorted[hi_rank]\n",
    "    # measure y wrt Qp\n",
    "    q_idx = int(np.floor(p*n))\n",
    "    Qp = x_sorted[q_idx]\n",
    "    y = (x <= Qp).astype(float)\n",
    "    ybar = y.mean()\n",
    "    se_adj = np.sqrt(ybar*(1-ybar)/n)\n",
    "    corr_factor = se_adj / se_naive\n",
    "    # post-adjust\n",
    "    mid_lo = lo_unadj - (Qp - lo_unadj)*corr_factor\n",
    "    mid_hi = hi_unadj + (hi_unadj - Qp)*corr_factor\n",
    "    return min(mid_lo, lo_unadj), max(mid_hi, hi_unadj)\n",
    "\n",
    "def run_simulation(n=1000, p=0.95, M=200):\n",
    "    true_q = true_quantile_normal(p)\n",
    "    methods = ['NB','Pre','Post']\n",
    "    coverage = {m:0 for m in methods}\n",
    "    runtime  = {m:0.0 for m in methods}\n",
    "    for _ in range(M):\n",
    "        x = np.random.randn(n)\n",
    "        # NB\n",
    "        t0 = time.time()\n",
    "        l_nb, h_nb = bootstrap_ci(x, p)\n",
    "        runtime['NB'] += (time.time() - t0)\n",
    "        coverage['NB'] += (l_nb <= true_q <= h_nb)\n",
    "        # Pre\n",
    "        t0 = time.time()\n",
    "        l_pre, h_pre = outer_ci_pre(x, p)\n",
    "        runtime['Pre'] += (time.time() - t0)\n",
    "        coverage['Pre'] += (l_pre <= true_q <= h_pre)\n",
    "        # Post\n",
    "        t0 = time.time()\n",
    "        l_post, h_post = outer_ci_post(x, p)\n",
    "        runtime['Post'] += (time.time() - t0)\n",
    "        coverage['Post'] += (l_post <= true_q <= h_post)\n",
    "    res = []\n",
    "    for m in methods:\n",
    "        res.append([m, coverage[m]/M, runtime[m]/M])\n",
    "    return pd.DataFrame(res, columns=['Method','Coverage','Avg Time (s)'])\n",
    "\n",
    "df_results = run_simulation(n=1000, p=0.95, M=200)\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

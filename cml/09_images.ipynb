{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device= cpu\n",
      "True ATE in test_ds= 0.4834\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MLPAlphaBeta Train: 100%|██████████| 500/500 [08:20<00:00,  1.00s/it]\n",
      "CNNAlphaBeta Train: 100%|██████████| 500/500 [17:00<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTS TABLE ===\n",
      "DataN | Model |   ATE_est |   ATE_se |   RMSE(y) |  R2(y)  |  RMSE(a) |  R2(a)  |  RMSE(b) |  R2(b)\n",
      "10000 MLP |   0.4299 |   0.0478 |   1.1034 |  -0.0175 |   0.4583 |  -1.6184 |   0.6377 |  -3.8884\n",
      "10000 CNN |   0.4292 |   0.0479 |   1.1038 |  -0.0183 |   0.4422 |  -1.4384 |   0.6228 |  -3.6626\n",
      "10000 CF  |   0.4907 |   0.0207 |      --  |   --   |    --    |   --   |   0.2885 |  -0.0006\n",
      "\n",
      "True ATE(test) = 0.4834\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Attempt imports for econml + LightGBM\n",
    "try:\n",
    "    from econml.dml import CausalForestDML\n",
    "    from lightgbm import LGBMRegressor\n",
    "    has_econml = True\n",
    "except ImportError:\n",
    "    has_econml = False\n",
    "    print(\"econml or lightgbm not installed. Please install them to use the CF approach.\")\n",
    "\n",
    "############################################################################\n",
    "# 1) DATASET + DATA GENERATION\n",
    "############################################################################\n",
    "\n",
    "def draw_x_shape(img_size=32, row=10, col=10):\n",
    "    \"\"\"\n",
    "    Draw a small 'X' in the image at (row,col).\n",
    "    We'll set a 3x3 cross for simplicity.\n",
    "    \"\"\"\n",
    "    img = np.zeros((img_size, img_size), dtype=np.float32)\n",
    "    # clamp row,col to avoid out-of-bounds\n",
    "    row = min(max(row,1), img_size-2)\n",
    "    col = min(max(col,1), img_size-2)\n",
    "    # center\n",
    "    img[row,   col]   = 1.0\n",
    "    # diagonals\n",
    "    img[row-1, col-1] = 1.0\n",
    "    img[row+1, col+1] = 1.0\n",
    "    img[row-1, col+1] = 1.0\n",
    "    img[row+1, col-1] = 1.0\n",
    "    return img\n",
    "\n",
    "class XShapeAlphaBeta(Dataset):\n",
    "    \"\"\"\n",
    "    For each sample:\n",
    "      - random row,col in [0..(img_size-1)]\n",
    "      - alpha = row / img_size\n",
    "      - beta  = col / img_size\n",
    "      - W ~ Bernoulli(0.5)\n",
    "      - Y = alpha + beta*W + noise\n",
    "      - image drawn with an 'X' at (row,col)\n",
    "    \"\"\"\n",
    "    def __init__(self, n=10000, img_size=32, seed=42):\n",
    "        super().__init__()\n",
    "        rng = np.random.default_rng(seed)\n",
    "        self.img_size = img_size\n",
    "        self.samples  = []\n",
    "        for _ in range(n):\n",
    "            row = rng.integers(0, img_size)\n",
    "            col = rng.integers(0, img_size)\n",
    "            alpha = row / img_size\n",
    "            beta  = col / img_size\n",
    "            w     = rng.binomial(1, 0.5)\n",
    "            noise = rng.standard_normal()\n",
    "            y     = alpha + beta*w + noise\n",
    "            img   = draw_x_shape(img_size, row, col)\n",
    "            self.samples.append((img, w, y, alpha, beta))\n",
    "\n",
    "        # \"true\" ATE ~ average beta\n",
    "        betas = [s[4] for s in self.samples]\n",
    "        self.true_ate = np.mean(betas)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]  # (img, w, y, alpha, beta)\n",
    "\n",
    "def collate_fn_synthetic(batch):\n",
    "    \"\"\"\n",
    "    batch => list of (img, w, y, alpha, beta)\n",
    "    We'll produce X_t => (batch,1,H,W), W_t => (batch,1), Y_t => (batch,1), alpha,beta => 1D\n",
    "    \"\"\"\n",
    "    imgs, w_list, y_list, alpha_list, beta_list = [], [], [], [], []\n",
    "    for (img, w, y, a, b) in batch:\n",
    "        imgs.append(img)\n",
    "        w_list.append(w)\n",
    "        y_list.append(y)\n",
    "        alpha_list.append(a)\n",
    "        beta_list.append(b)\n",
    "    # shape => (batch, H, W)\n",
    "    X_t = torch.tensor(imgs, dtype=torch.float32)\n",
    "    X_t = X_t.unsqueeze(1)  # => (batch,1,H,W)\n",
    "    W_t = torch.tensor(w_list, dtype=torch.float32).view(-1,1)\n",
    "    Y_t = torch.tensor(y_list, dtype=torch.float32).view(-1,1)\n",
    "    A_t = torch.tensor(alpha_list, dtype=torch.float32)\n",
    "    B_t = torch.tensor(beta_list, dtype=torch.float32)\n",
    "    return X_t, W_t, Y_t, A_t, B_t\n",
    "\n",
    "############################################################################\n",
    "# 2) MODELS\n",
    "############################################################################\n",
    "\n",
    "class MLPAlphaBeta(nn.Module):\n",
    "    \"\"\"\n",
    "    Flatten => MLP => (alpha,beta).\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=32, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        in_dim = img_size*img_size\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # x => (batch, 1, H, W)\n",
    "        b,c,h,w = x.shape\n",
    "        x_flat = x.view(b, -1)  # => (b, H*W)\n",
    "        ab_pred= self.net(x_flat)\n",
    "        return ab_pred\n",
    "\n",
    "class CNNAlphaBeta(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolution => final FC => (alpha,beta).\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=32):\n",
    "        super().__init__()\n",
    "        # small conv net\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,8, 3, padding=1),  # =>(8,H,W)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),              # =>(8,H/2,W/2)\n",
    "            nn.Conv2d(8,16,3, padding=1), # =>(16,H/2,W/2)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)               # =>(16,H/4,W/4)\n",
    "        )\n",
    "        # for 32 => after 2 pool => 8 => shape=16*8*8=1024\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16*(img_size//4)*(img_size//4), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        b,c,h,w= x.shape\n",
    "        h = self.conv(x)                # => (b,16,H/4,W/4)\n",
    "        h = h.view(b, -1)               # =>(b,16*(H/4)*(W/4))\n",
    "        ab= self.fc(h)                  # =>(b,2)\n",
    "        return ab\n",
    "\n",
    "############################################################################\n",
    "# 3) TRAIN + EVAL\n",
    "############################################################################\n",
    "\n",
    "def dr_ate(alpha_hat, beta_hat, w_arr, y_arr):\n",
    "    mu0= alpha_hat\n",
    "    mu1= alpha_hat + beta_hat\n",
    "    e= 0.5\n",
    "    IF= (mu1 + w_arr*(y_arr - mu1)/e) - (mu0 + (1-w_arr)*(y_arr - mu0)/(1-e))\n",
    "    ate= IF.mean()\n",
    "    se=  IF.std(ddof=1)/np.sqrt(len(IF))\n",
    "    return ate, se\n",
    "\n",
    "def rmse(true_vals, pred_vals):\n",
    "    return np.sqrt(np.mean((true_vals - pred_vals)**2))\n",
    "\n",
    "def r2_score(true_vals, pred_vals):\n",
    "    true_vals= np.array(true_vals)\n",
    "    pred_vals= np.array(pred_vals)\n",
    "    sse= np.sum((true_vals - pred_vals)**2)\n",
    "    sst= np.sum((true_vals - np.mean(true_vals))**2)\n",
    "    return 1.0 - sse/sst if sst>1e-8 else 0.0\n",
    "\n",
    "def evaluate_model(model, loader, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluate param. model => (ATE,SE, RMSE(y), R2(y), RMSE(a), R2(a), RMSE(b), R2(b))\n",
    "    CF doesn't produce alpha or Y => we'll handle separately\n",
    "    \"\"\"\n",
    "    alphaP, betaP= [], []\n",
    "    alphaT, betaT= [], []\n",
    "    w_arr, y_arr= [], []\n",
    "    y_pred= []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (X_t,W_t,Y_t,A_t,B_t) in loader:\n",
    "            X_t= X_t.to(device)\n",
    "            ab= model(X_t)  # =>(batch,2)\n",
    "            alpha_hat= ab[:,0]\n",
    "            beta_hat = ab[:,1]\n",
    "            alphaP.extend(alpha_hat.cpu().numpy().tolist())\n",
    "            betaP.extend(beta_hat.cpu().numpy().tolist())\n",
    "\n",
    "            alphaT.extend(A_t.numpy().tolist())\n",
    "            betaT.extend(B_t.numpy().tolist())\n",
    "            w_arr.extend(W_t.view(-1).numpy().tolist())\n",
    "            y_arr.extend(Y_t.view(-1).numpy().tolist())\n",
    "\n",
    "            y_hat= alpha_hat + beta_hat*W_t.to(device).view(-1)\n",
    "            y_pred.extend(y_hat.cpu().numpy().tolist())\n",
    "    # arrays\n",
    "    alphaP= np.array(alphaP)\n",
    "    betaP=  np.array(betaP)\n",
    "    alphaT= np.array(alphaT)\n",
    "    betaT=  np.array(betaT)\n",
    "    w_arr=  np.array(w_arr)\n",
    "    y_arr=  np.array(y_arr)\n",
    "    y_pred= np.array(y_pred)\n",
    "\n",
    "    # ATE, SE\n",
    "    ate_est, ate_se= dr_ate(alphaP, betaP, w_arr, y_arr)\n",
    "\n",
    "    # RMSE+R2(Y)\n",
    "    rmse_y= rmse(y_arr, y_pred)\n",
    "    r2y   = r2_score(y_arr, y_pred)\n",
    "\n",
    "    # RMSE+R2(alpha)\n",
    "    rmse_a= rmse(alphaT, alphaP)\n",
    "    r2a   = r2_score(alphaT, alphaP)\n",
    "\n",
    "    # RMSE+R2(beta)\n",
    "    rmse_b= rmse(betaT, betaP)\n",
    "    r2b   = r2_score(betaT, betaP)\n",
    "    return (ate_est, ate_se, rmse_y, r2y, rmse_a, r2a, rmse_b, r2b)\n",
    "\n",
    "def train(model, loader, optimizer, epochs=15, device='cpu'):\n",
    "    \"\"\"Train param. model => MLP or CNN => predict (alpha,beta).\"\"\"\n",
    "    mse= nn.MSELoss()\n",
    "    model.train()\n",
    "    for ep in tqdm(range(epochs), desc=f\"{model.__class__.__name__} Train\"):\n",
    "        for (X_t,W_t,Y_t,_,_) in loader:\n",
    "            X_t= X_t.to(device)\n",
    "            W_t= W_t.to(device)\n",
    "            Y_t= Y_t.to(device)\n",
    "            ab= model(X_t)             # =>(batch,2)\n",
    "            alpha_pred= ab[:,0:1]\n",
    "            beta_pred= ab[:,1:2]\n",
    "            y_hat= alpha_pred + beta_pred*W_t\n",
    "            loss= mse(y_hat, Y_t)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "############################################################################\n",
    "# 4) CAUSAL FOREST + UTIL\n",
    "############################################################################\n",
    "\n",
    "def prepare_cf_data(samples):\n",
    "    \"\"\"\n",
    "    Flatten each (img) => X, also store W,Y,beta for CF metrics\n",
    "    \"\"\"\n",
    "    X_list, W_list, Y_list, B_list= [],[],[],[]\n",
    "    for (img,w,y,a,b) in samples:\n",
    "        # flatten image => shape= (H*W,) => in this case 32*32=1024\n",
    "        X_list.append(img.flatten())\n",
    "        W_list.append(w)\n",
    "        Y_list.append(y)\n",
    "        B_list.append(b)\n",
    "    X_np= np.array(X_list,dtype=np.float32)\n",
    "    W_np= np.array(W_list,dtype=np.float32)\n",
    "    Y_np= np.array(Y_list,dtype=np.float32)\n",
    "    B_np= np.array(B_list,dtype=np.float32)\n",
    "    return X_np, W_np, Y_np, B_np\n",
    "\n",
    "############################################################################\n",
    "# 5) MAIN\n",
    "############################################################################\n",
    "\n",
    "def main():\n",
    "    device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device= {device}\")\n",
    "\n",
    "    # 1) We'll define a single test set\n",
    "    test_ds= XShapeAlphaBeta(n=2000, img_size=32, seed=999)\n",
    "    test_loader= DataLoader(test_ds, batch_size=64, shuffle=False, collate_fn=collate_fn_synthetic)\n",
    "    print(f\"True ATE in test_ds= {test_ds.true_ate:.4f}\\n\")\n",
    "\n",
    "    # 2) We'll run for these training set sizes\n",
    "    train_sizes= [10_000]\n",
    "    epochs= 500  # or more if you want\n",
    "\n",
    "    # We'll store table rows as: (N, Model, ATE, SE, RMSEy, R2y, RMSEa, R2a, RMSEb, R2b)\n",
    "    results= []\n",
    "\n",
    "    def run_exp(N):\n",
    "        # Build train dataset\n",
    "        train_ds= XShapeAlphaBeta(n=N, img_size=32, seed=42)\n",
    "        train_loader= DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=collate_fn_synthetic)\n",
    "\n",
    "        # (A) MLP\n",
    "        mlp_model= MLPAlphaBeta(img_size=32).to(device)\n",
    "        opt_mlp= optim.Adam(mlp_model.parameters(), lr=1e-3)\n",
    "        train(mlp_model, train_loader, opt_mlp, epochs=epochs, device=device)\n",
    "        mlp_res= evaluate_model(mlp_model, test_loader, device=device)\n",
    "\n",
    "        # (B) CNN\n",
    "        cnn_model= CNNAlphaBeta(img_size=32).to(device)\n",
    "        opt_cnn= optim.Adam(cnn_model.parameters(), lr=1e-3)\n",
    "        train(cnn_model, train_loader, opt_cnn, epochs=epochs, device=device)\n",
    "        cnn_res= evaluate_model(cnn_model, test_loader, device=device)\n",
    "\n",
    "        # (C) CF, if econml available\n",
    "        if has_econml:\n",
    "            from econml.dml import CausalForestDML\n",
    "            from lightgbm import LGBMRegressor\n",
    "            X_cf_train, W_cf_train, Y_cf_train, B_cf_train= prepare_cf_data(train_ds)\n",
    "            X_cf_test,  W_cf_test,  Y_cf_test,  B_cf_test=  prepare_cf_data(test_ds)\n",
    "            cf= CausalForestDML(\n",
    "                model_y= LGBMRegressor(verbose=-1),\n",
    "                model_t= LGBMRegressor(verbose=-1),\n",
    "                n_estimators=400,\n",
    "                min_samples_leaf=10,\n",
    "                max_depth=25,\n",
    "                random_state=42\n",
    "            )\n",
    "            cf.fit(Y_cf_train, W_cf_train, X=X_cf_train)\n",
    "            b_hat_cf= cf.effect(X_cf_test)  # shape=(len(test),)\n",
    "            ate_cf= np.mean(b_hat_cf)\n",
    "            # naive se\n",
    "            lb_cf, ub_cf= cf.effect_interval(X_cf_test)\n",
    "            se_cf= (ub_cf - lb_cf).mean()/(2*1.96)\n",
    "\n",
    "            # compare b_hat_cf to true beta => RMSE, R2\n",
    "            def rmse(a,b): return np.sqrt(np.mean((a-b)**2))\n",
    "            rb_cf= rmse(B_cf_test, b_hat_cf)\n",
    "            r2b_cf= r2_score(B_cf_test, b_hat_cf)\n",
    "            # CF => no alpha or Y => placeholders => (ate,se, None, None, None, None, rmseB, r2B)\n",
    "            cf_res= (ate_cf, se_cf, None, None, None, None, rb_cf, r2b_cf)\n",
    "        else:\n",
    "            cf_res= (np.nan, np.nan, None, None, None, None, None, None)\n",
    "\n",
    "        return mlp_res, cnn_res, cf_res\n",
    "\n",
    "    # 3) Loop over train_sizes\n",
    "    for N in train_sizes:\n",
    "        mlpR, cnnR, cfR= run_exp(N)\n",
    "\n",
    "        # MLP => (ate,se, rmse_y, r2_y, rmse_a, r2_a, rmse_b, r2_b)\n",
    "        results.append( (N,\"MLP\", *mlpR) )\n",
    "        # CNN => (ate,se, rmse_y, r2_y, rmse_a, r2_a, rmse_b, r2_b)\n",
    "        results.append( (N,\"CNN\", *cnnR) )\n",
    "        # CF => (ate,se, None, None, None, None, rb, r2b)\n",
    "        results.append( (N,\"CF\",  *cfR) )\n",
    "\n",
    "    # 4) Print final table\n",
    "    print(\"\\n=== RESULTS TABLE ===\")\n",
    "    print(\"DataN | Model |   ATE_est |   ATE_se |   RMSE(y) |  R2(y)  |  RMSE(a) |  R2(a)  |  RMSE(b) |  R2(b)\")\n",
    "    for row in results:\n",
    "        (N,model,ate,se, ry,r2y, ra,r2a, rb,r2b)= row\n",
    "        # if CF => no alpha,y\n",
    "        if model==\"CF\":\n",
    "            ate_s= f\"{ate:8.4f}\" if not np.isnan(ate) else \"   --\"\n",
    "            se_s=  f\"{se:8.4f}\"  if not np.isnan(se)  else \"   --\"\n",
    "            rb_s=  f\"{rb:8.4f}\"  if (rb is not None)  else \"   --\"\n",
    "            r2b_s= f\"{r2b:8.4f}\" if (r2b is not None) else \"   --\"\n",
    "            print(f\"{N:<5} {model:<3} | {ate_s} | {se_s} |      --  |   --   |    --    |   --   | {rb_s} | {r2b_s}\")\n",
    "        else:\n",
    "            ate_s= f\"{ate:8.4f}\"\n",
    "            se_s=  f\"{se:8.4f}\"\n",
    "            ry_s=  f\"{ry:8.4f}\"  if ry is not None else \"   --\"\n",
    "            r2y_s= f\"{r2y:8.4f}\" if r2y is not None else \"   --\"\n",
    "            ra_s=  f\"{ra:8.4f}\"  if ra is not None else \"   --\"\n",
    "            r2a_s= f\"{r2a:8.4f}\" if r2a is not None else \"   --\"\n",
    "            rb_s=  f\"{rb:8.4f}\"  if rb is not None else \"   --\"\n",
    "            r2b_s= f\"{r2b:8.4f}\" if r2b is not None else \"   --\"\n",
    "            print(f\"{N:<5} {model:<3} | {ate_s} | {se_s} | {ry_s} | {r2y_s} | {ra_s} | {r2a_s} | {rb_s} | {r2b_s}\")\n",
    "\n",
    "    print(f\"\\nTrue ATE(test) = {test_ds.true_ate:.4f}\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
